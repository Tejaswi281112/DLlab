import tensorflow as tf
from tensorflow import keras
from tensorflow.keras.layers import Dense, Dropout
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
import numpy as np

# Generate synthetic data
np.random.seed(42)
X = np.random.rand(1000, 5)  # 5 features
y = 3 * X[:, 0] + 2 * X[:, 1] + 5 * X[:, 2] + np.random.randn(1000) * 0.1  # Linear function + noise

# Train-test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Standardize data
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# Build Model with Dropout
model = keras.Sequential([
    Dense(128, activation='relu', input_shape=(5,)),
    Dropout(0.3),  # Drops 30% of neurons
    Dense(64, activation='relu'),
    Dropout(0.3),  
    Dense(1)  # Regression output
])

# Compile Model
model.compile(optimizer='adam', loss='mse', metrics=['mae'])

# Train Model
model.fit(X_train, y_train, epochs=50, batch_size=16, validation_data=(X_test, y_test), verbose=1)

# Evaluate Model
loss, mae = model.evaluate(X_test, y_test)
print(f"Test MAE: {mae:.4f}")
